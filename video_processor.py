#!/usr/bin/env python3
"""
Video Processor - Stage 1: Detecci√≥n y Extracci√≥n de Personas

Este script implementa el primer stage de un sistema de detecci√≥n de riesgo.
Procesa un video frame por frame y extrae im√°genes de todas las personas detectadas
utilizando YOLOv8 pre-entrenado en el dataset COCO.

Autor: Proyecto de Procesamiento de Im√°genes - Universidad Nacional de Luj√°n
Fecha: Septiembre 2025
"""

import cv2
import os
from pathlib import Path
from ultralytics import YOLO
import argparse
from typing import List, Tuple

# Configuraci√≥n de rutas por defecto
DEFAULT_VIDEO_PATH = 'input/test_video.mp4'  # Placeholder para el video de entrada
DEFAULT_OUTPUT_DIR = 'output/cropped_persons'  # Directorio de salida para personas extra√≠das

# Variables globales que se actualizar√°n con argumentos
VIDEO_PATH = DEFAULT_VIDEO_PATH
OUTPUT_DIR = DEFAULT_OUTPUT_DIR

# ID de la clase 'person' en el dataset COCO
PERSON_CLASS_ID = 0

def setup_directories() -> None:
    """
    Crea los directorios necesarios si no existen.
    
    Crea:
    - Directorio de entrada (input/)
    - Directorio de salida (output/cropped_persons/)
    """
    Path('input').mkdir(exist_ok=True)
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    print(f"‚úÖ Directorios configurados:")
    print(f"   - Entrada: input/")
    print(f"   - Salida: {OUTPUT_DIR}/")

def load_yolo_model() -> YOLO:
    """
    Carga el modelo YOLOv8n pre-entrenado en COCO.
    
    Returns:
        YOLO: Modelo YOLOv8n listo para inferencia
        
    Notes:
        - Usa YOLOv8n (nano) por su eficiencia y velocidad
        - El modelo est√° pre-entrenado en COCO dataset
        - Incluye la clase 'person' con ID=0
    """
    print("üîÑ Cargando modelo YOLOv8n...")
    model = YOLO('yolov8n.pt')  # Descarga autom√°ticamente si no existe
    print("‚úÖ Modelo YOLOv8n cargado exitosamente")
    print(f"   - Arquitectura: CNN de una sola etapa (single-stage)")
    print(f"   - Dataset de entrenamiento: COCO (80 clases)")
    print(f"   - Clase objetivo: 'person' (ID: {PERSON_CLASS_ID})")
    return model

def extract_person_crops(frame: cv2.Mat, results, frame_number: int) -> int:
    """
    Extrae y guarda recortes de todas las personas detectadas en un frame.
    
    Args:
        frame: Frame del video (imagen BGR)
        results: Resultados de la inferencia YOLOv8
        frame_number: N√∫mero del frame actual
        
    Returns:
        int: N√∫mero de personas detectadas y guardadas
    """
    persons_detected = 0
    
    # Procesar cada detecci√≥n en el frame
    for result in results:
        boxes = result.boxes
        if boxes is not None:
            for i, box in enumerate(boxes):
                # Filtrar solo detecciones de la clase 'person' (ID: 0)
                class_id = int(box.cls[0])
                confidence = float(box.conf[0])
                
                if class_id == PERSON_CLASS_ID and confidence > 0.5:  # Umbral de confianza
                    # Obtener coordenadas de la bounding box
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    
                    # Asegurar que las coordenadas est√©n dentro de los l√≠mites del frame
                    h, w = frame.shape[:2]
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(w, x2), min(h, y2)
                    
                    # Recortar la regi√≥n de la persona
                    person_crop = frame[y1:y2, x1:x2]
                    
                    if person_crop.size > 0:  # Verificar que el recorte no est√© vac√≠o
                        # Generar nombre del archivo
                        filename = f"frame_{frame_number:06d}_person_{i+1}_conf_{confidence:.2f}.jpg"
                        filepath = os.path.join(OUTPUT_DIR, filename)
                        
                        # Guardar el recorte
                        cv2.imwrite(filepath, person_crop)
                        persons_detected += 1
                        
                        print(f"   üíæ Guardado: {filename} (conf: {confidence:.2f})")
    
    return persons_detected

def process_video(video_path: str, model: YOLO) -> Tuple[int, int]:
    """
    Procesa un video completo y extrae todas las personas detectadas.
    
    Args:
        video_path: Ruta al archivo de video
        model: Modelo YOLOv8 cargado
        
    Returns:
        Tuple[int, int]: (total_frames_procesados, total_personas_extra√≠das)
    """
    # Abrir el video
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"‚ùå Error: No se pudo abrir el video {video_path}")
    
    # Obtener informaci√≥n del video
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"\nüìπ Informaci√≥n del video:")
    print(f"   - Frames totales: {total_frames}")
    print(f"   - FPS: {fps:.2f}")
    print(f"   - Duraci√≥n: {duration:.2f} segundos")
    print(f"\nüöÄ Iniciando procesamiento...")
    
    frame_count = 0
    total_persons = 0
    
    try:
        while True:
            # Leer frame por frame
            ret, frame = cap.read()
            if not ret:
                break  # Fin del video
            
            frame_count += 1
            
            # Mostrar progreso cada 30 frames
            if frame_count % 30 == 0 or frame_count == 1:
                progress = (frame_count / total_frames) * 100
                print(f"\nüîç Frame {frame_count}/{total_frames} ({progress:.1f}%)")
            
            # Realizar inferencia con YOLOv8
            # verbose=False para reducir output del modelo
            results = model(frame, verbose=False)
            
            # Extraer y guardar personas detectadas
            persons_in_frame = extract_person_crops(frame, results, frame_count)
            total_persons += persons_in_frame
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Procesamiento interrumpido por el usuario")
    finally:
        cap.release()
    
    return frame_count, total_persons

def main():
    """
    Funci√≥n principal del programa.
    
    Flujo de trabajo:
    1. Configurar directorios
    2. Cargar modelo YOLOv8
    3. Procesar video frame por frame
    4. Detectar personas usando YOLO
    5. Extraer y guardar recortes de personas
    6. Mostrar estad√≠sticas finales
    """
    print("üéØ Stage 1: Detecci√≥n y Extracci√≥n de Personas")
    print("=" * 50)
    
    # Configurar argumentos de l√≠nea de comandos
    parser = argparse.ArgumentParser(
        description="Extrae personas de un video usando YOLOv8"
    )
    parser.add_argument(
        '--video', '-v',
        type=str,
        default=DEFAULT_VIDEO_PATH,
        help=f"Ruta al video de entrada (default: {DEFAULT_VIDEO_PATH})"
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=DEFAULT_OUTPUT_DIR,
        help=f"Directorio de salida (default: {DEFAULT_OUTPUT_DIR})"
    )
    
    args = parser.parse_args()
    
    # Actualizar rutas con argumentos
    global VIDEO_PATH, OUTPUT_DIR
    VIDEO_PATH = args.video
    OUTPUT_DIR = args.output
    
    try:
        # 1. Configurar directorios
        setup_directories()
        
        # 2. Verificar que existe el video
        if not os.path.exists(VIDEO_PATH):
            print(f"\n‚ùå Error: Video no encontrado en {VIDEO_PATH}")
            print(f"   Coloca tu video en la carpeta 'input/' o especifica la ruta con --video")
            return
        
        # 3. Cargar modelo YOLOv8
        model = load_yolo_model()
        
        # 4. Procesar video
        frames_processed, total_persons = process_video(VIDEO_PATH, model)
        
        # 5. Mostrar estad√≠sticas finales
        print("\n" + "=" * 50)
        print("üìä RESUMEN DEL PROCESAMIENTO")
        print("=" * 50)
        print(f"‚úÖ Frames procesados: {frames_processed}")
        print(f"üë• Personas extra√≠das: {total_persons}")
        print(f"üìÅ Im√°genes guardadas en: {OUTPUT_DIR}/")
        print(f"\nüéØ Stage 1 completado exitosamente!")
        print(f"üí° Las im√°genes extra√≠das est√°n listas para el Stage 2")
        print(f"   (Fine-tuning para detecci√≥n de armas)")
        
    except Exception as e:
        print(f"\n‚ùå Error durante el procesamiento: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())