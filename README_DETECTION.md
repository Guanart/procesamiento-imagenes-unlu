# Stage 1: DetecciÃ³n de Personas y ExtracciÃ³n de ImÃ¡genes

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa el **Stage 1** de un sistema de detecciÃ³n de riesgo en dos etapas. El objetivo principal es procesar videos y extraer imÃ¡genes de todas las personas detectadas, preparando el dataset para una segunda fase de anÃ¡lisis enfocada en la detecciÃ³n de armas.

### ğŸ¯ Objetivo

Desarrollar un sistema automatizado que:
- Procese videos frame por frame
- Detecte personas usando inteligencia artificial
- Extraiga y guarde imÃ¡genes recortadas de cada persona
- Prepare el dataset para el Stage 2 (detecciÃ³n de armas)

---

## ğŸ§  FundamentaciÃ³n del Modelo y Arquitectura

### Modelo Seleccionado: YOLOv8n

**YOLOv8n** (You Only Look Once - versiÃ³n nano) ha sido seleccionado como el modelo base para este proyecto por las siguientes razones tÃ©cnicas:

#### CaracterÃ­sticas TÃ©cnicas:
- **Arquitectura**: Red Neuronal Convolucional (CNN) de una sola etapa (*single-stage*)
- **Eficiencia**: VersiÃ³n nano optimizada para velocidad y bajo consumo de recursos
- **PrecisiÃ³n**: Mantiene alta accuracy mientras reduce el tiempo de inferencia
- **Fuente**: [Repositorio oficial de Ultralytics en GitHub](https://github.com/ultralytics/ultralytics)

#### Ventajas de YOLOv8n:
1. **DetecciÃ³n en Tiempo Real**: Capaz de procesar mÃºltiples frames por segundo
2. **Arquitectura Unificada**: Un solo modelo maneja localizaciÃ³n y clasificaciÃ³n simultÃ¡neamente
3. **OptimizaciÃ³n de Recursos**: La versiÃ³n nano requiere menos memoria y procesamiento
4. **Pre-entrenamiento COCO**: Ya optimizado para detectar la clase 'persona'

### Tipo de Red Neural

**Arquitectura CNN de Una Sola Etapa (Single-Stage)**:
- **Ventaja Principal**: Realiza detecciÃ³n y localizaciÃ³n en una sola pasada
- **Eficiencia**: MÃ¡s rÃ¡pido que arquitecturas de dos etapas (R-CNN, Fast R-CNN)
- **Aplicabilidad**: Ideal para procesamiento de video en tiempo real

---

## ğŸ“Š JustificaciÃ³n del Pre-entrenamiento: COCO vs. ImageNet

### Â¿Por quÃ© COCO Dataset?

La elecciÃ³n del dataset COCO sobre ImageNet se fundamenta en los siguientes aspectos tÃ©cnicos:

#### **COCO Dataset - La ElecciÃ³n Correcta**:
- **Tarea EspecÃ­fica**: Entrenado para **DetecciÃ³n de Objetos** (Object Detection)
- **LocalizaciÃ³n Espacial**: Incluye coordenadas de *bounding boxes*
- **Clase 'Person'**: La clase `person` (ID: 0) estÃ¡ altamente optimizada
- **Diversidad**: 80 clases de objetos cotidianos con variaciones contextuales
- **Robustez**: Entrenado con imÃ¡genes en mÃºltiples condiciones (iluminaciÃ³n, Ã¡ngulos, oclusiones)

#### **ImageNet - Limitaciones para Nuestro Caso**:
- **Tarea Diferente**: Enfocado en **ClasificaciÃ³n de ImÃ¡genes** solamente
- **Sin LocalizaciÃ³n**: No proporciona informaciÃ³n espacial de objetos
- **Inadecuado**: RequerirÃ­a arquitectura adicional para detecciÃ³n

### Beneficios EspecÃ­ficos para el Stage 1:

1. **OptimizaciÃ³n Inmediata**: El modelo YOLOv8n + COCO ya estÃ¡ optimizado para detectar personas
2. **Sin Reentrenamiento**: No requiere fine-tuning para el Stage 1
3. **Alta PrecisiÃ³n**: Accuracy superior al 90% en detecciÃ³n de personas
4. **PreparaciÃ³n Stage 2**: Las imÃ¡genes extraÃ­das son ideales para entrenar detectores de armas

---

## ğŸ”„ MetodologÃ­a y PreparaciÃ³n para el Stage 2

### Flujo de Trabajo del Stage 1:

```
Video de Entrada â†’ ExtracciÃ³n de Frames â†’ YOLOv8 Inferencia â†’ Filtrado ('person' solamente) â†’ Recorte de Bounding Boxes â†’ Almacenamiento Organizado
```

#### Proceso Detallado:

1. **Lectura de Video**: 
   - Procesamiento frame por frame usando OpenCV
   - Mantenimiento de metadatos (nÃºmero de frame, timestamp)

2. **Inferencia YOLOv8**:
   - DetecciÃ³n de todos los objetos en cada frame
   - Filtrado especÃ­fico para clase `person` (ID: 0)
   - AplicaciÃ³n de umbral de confianza (>0.5)

3. **ExtracciÃ³n y Recorte**:
   - CÃ¡lculo de coordenadas de bounding box
   - Recorte preciso de la regiÃ³n de la persona
   - ValidaciÃ³n de dimensiones mÃ­nimas

4. **Almacenamiento Estructurado**:
   - Nomenclatura sistemÃ¡tica: `frame_XXXXXX_person_X_conf_X.XX.jpg`
   - OrganizaciÃ³n por confianza y frame de origen
   - Metadatos preservados en el nombre del archivo

### Dataset de Salida para Stage 2:

Las imÃ¡genes generadas por el Stage 1 constituyen el **Dataset de Entrada** para el **Stage 2**, donde se realizarÃ¡:

- **Fine-tuning** del modelo para detectar objetos especÃ­ficos (`pistola`, `cuchillo`)
- **Transfer Learning** desde detecciÃ³n de personas a detecciÃ³n de armas
- **Entrenamiento Supervisado** con las imÃ¡genes de personas como input

#### Ventajas del Dataset Generado:
- **Relevancia Contextual**: Solo contiene personas (contexto apropiado para armas)
- **Diversidad Visual**: Diferentes poses, Ã¡ngulos y condiciones
- **Calidad Controlada**: Filtrado por confianza garantiza calidad mÃ­nima
- **Escalabilidad**: Procesamiento automatizado permite grandes volÃºmenes

---

## ğŸš€ Instrucciones de Uso

### Requisitos del Sistema

- **Python**: 3.8 o superior
- **GPU**: Recomendada para procesamiento rÃ¡pido (CUDA compatible)
- **RAM**: MÃ­nimo 4GB, recomendado 8GB
- **Espacio**: Dependiente del tamaÃ±o del video y personas detectadas

### InstalaciÃ³n

1. **Clonar/Descargar el proyecto**:
   ```bash
   cd procesamiento-imagenes-unlu
   ```

2. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```
   
   Las dependencias principales incluyen:
   - `ultralytics>=8.0.0` - Framework YOLOv8
   - `opencv-python>=4.8.0` - Procesamiento de video
   - `torch>=2.0.0` - Backend de deep learning
   - `torchvision>=0.15.0` - Utilidades de visiÃ³n por computadora

3. **Preparar video de entrada**:
   ```bash
   mkdir -p input
   # Colocar video en input/test_video.mp4 o especificar ruta
   ```

### EjecuciÃ³n

#### Uso BÃ¡sico:
```bash
python video_processor.py
```

#### Uso Avanzado:
```bash
# Especificar video personalizado
python video_processor.py --video mi_video.mp4

# Especificar directorio de salida personalizado
python video_processor.py --output mi_directorio_salida

# CombinaciÃ³n de parÃ¡metros
python video_processor.py --video videos/seguridad.mp4 --output resultados/personas
```

### ParÃ¡metros de ConfiguraciÃ³n:

- `--video, -v`: Ruta al video de entrada (default: `input/test_video.mp4`)
- `--output, -o`: Directorio de salida (default: `output/cropped_persons`)

---

## ğŸ“ Estructura de Archivos

```
procesamiento-imagenes-unlu/
â”œâ”€â”€ video_processor.py          # Script principal
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ README.md                 # Esta documentaciÃ³n
â”œâ”€â”€ input/                    # Videos de entrada
â”‚   â””â”€â”€ test_video.mp4       # Video de prueba
â””â”€â”€ output/                   # Resultados
    â””â”€â”€ cropped_persons/      # ImÃ¡genes de personas extraÃ­das
        â”œâ”€â”€ frame_000001_person_1_conf_0.85.jpg
        â”œâ”€â”€ frame_000001_person_2_conf_0.92.jpg
        â””â”€â”€ ...
```

---

## ğŸ“Š Salida y Resultados

### InformaciÃ³n Durante la EjecuciÃ³n:

El script proporciona informaciÃ³n detallada en tiempo real:
- Progreso del procesamiento (% completado)
- NÃºmero de personas detectadas por frame
- Nivel de confianza de cada detecciÃ³n
- EstadÃ­sticas finales del procesamiento

### Ejemplo de Salida:
```
ğŸ¯ Stage 1: DetecciÃ³n y ExtracciÃ³n de Personas
==================================================
âœ… Directorios configurados:
   - Entrada: input/
   - Salida: output/cropped_persons/

ğŸ”„ Cargando modelo YOLOv8n...
âœ… Modelo YOLOv8n cargado exitosamente
   - Arquitectura: CNN de una sola etapa (single-stage)
   - Dataset de entrenamiento: COCO (80 clases)
   - Clase objetivo: 'person' (ID: 0)

ğŸ“¹ InformaciÃ³n del video:
   - Frames totales: 1500
   - FPS: 30.00
   - DuraciÃ³n: 50.00 segundos

ğŸš€ Iniciando procesamiento...

ğŸ” Frame 30/1500 (2.0%)
   ğŸ’¾ Guardado: frame_000030_person_1_conf_0.87.jpg (conf: 0.87)
   ğŸ’¾ Guardado: frame_000030_person_2_conf_0.92.jpg (conf: 0.92)

==================================================
ğŸ“Š RESUMEN DEL PROCESAMIENTO
==================================================
âœ… Frames procesados: 1500
ğŸ‘¥ Personas extraÃ­das: 342
ğŸ“ ImÃ¡genes guardadas en: output/cropped_persons/

ğŸ¯ Stage 1 completado exitosamente!
ğŸ’¡ Las imÃ¡genes extraÃ­das estÃ¡n listas para el Stage 2
   (Fine-tuning para detecciÃ³n de armas)
```

---

## ğŸ”¬ Consideraciones TÃ©cnicas

### Optimizaciones Implementadas:

1. **Umbral de Confianza**: Filtrado a 0.5 para balance precisiÃ³n/recall
2. **ValidaciÃ³n de Coordenadas**: VerificaciÃ³n de lÃ­mites del frame
3. **Manejo de Memoria**: LiberaciÃ³n de recursos por frame
4. **Nomenclatura SistemÃ¡tica**: Trazabilidad completa del origen

### Limitaciones Conocidas:

1. **Oclusiones Parciales**: Personas parcialmente ocultas pueden no detectarse
2. **ResoluciÃ³n MÃ­nima**: Personas muy pequeÃ±as (<20px) pueden ignorarse
3. **Condiciones Extremas**: IluminaciÃ³n muy pobre puede afectar detecciÃ³n

### Recomendaciones para Mejores Resultados:

1. **Calidad de Video**: Usar resoluciÃ³n HD o superior
2. **IluminaciÃ³n**: Evitar videos con iluminaciÃ³n extremadamente pobre
3. **Estabilidad**: Videos estables reducen falsos positivos por blur

---

## ğŸ“š Referencias y Fuentes

### DocumentaciÃ³n TÃ©cnica:
- [YOLOv8 Official Documentation](https://docs.ultralytics.com/)
- [COCO Dataset Paper](https://arxiv.org/abs/1405.0312)
- [OpenCV Video Documentation](https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html)

### InvestigaciÃ³n AcadÃ©mica:
- Redmon, J., et al. "You Only Look Once: Unified, Real-Time Object Detection" (2016)
- Lin, T.-Y., et al. "Microsoft COCO: Common Objects in Context" (2014)
- Jocher, G., et al. "YOLOv8: A new state-of-the-art computer vision model" (2023)

### Repositorios de CÃ³digo:
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [OpenCV Python](https://github.com/opencv/opencv-python)

---

## ğŸ‘¨â€ğŸ’» InformaciÃ³n del Desarrollo

**Proyecto**: Procesamiento de ImÃ¡genes - Universidad Nacional de LujÃ¡n  
**Curso**: Procesamiento Digital de ImÃ¡genes  
**Fecha**: Septiembre 2025  
**TecnologÃ­as**: Python, YOLOv8, OpenCV, PyTorch  

**Objetivo AcadÃ©mico**: Demostrar la aplicaciÃ³n prÃ¡ctica de tÃ©cnicas de Computer Vision en sistemas de detecciÃ³n automatizada, preparando la base para anÃ¡lisis de seguridad mÃ¡s avanzados.

---

*Este documento proporciona la fundamentaciÃ³n completa del Stage 1 del sistema de detecciÃ³n. Para consultas tÃ©cnicas o mejoras, referirse a la documentaciÃ³n oficial de las librerÃ­as utilizadas.*